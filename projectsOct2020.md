# Project Offerings

# Lovelab ([bradlove.org](http://bradlove.org)), a computational cognitive science lab directed by Prof Brad Love.


We are looking for enthusiastic and motivated students who want to collaborate with Prof Brad Love and members of his [lab](http://bradlove.org). We aim to improve performance of neural network models and make them more human-like by using insights from neuroscience. Students with approrpriate skills with a strong interest in training and evaluating convolutional neural networks should contact Prof Love, b.love@ucl.ac.uk.

## Prerequisites

I am getting some emails from enthusiastic students (always great) who unfortunately do not have the backgrounds to complete the projects below. Students are going to need an undergraduate degree in computer science degree or closely related field. Students must be proficient in Python and familiar with TensorFlow and/or PyTorch. Students should also be comfortable with linear algebra, multivariate calculus, version control (git), and version control repositories (GitHub). These are not concepts that we are going to teach or tasks my lab will do for you, but the starting points for your project work. We are here to do MSc level research with you, not provide undergraduate training in computer science. There simply isn't enough time to master these basic concepts and also do the project work.

## 1. Unsupervised Task Learning 
Much of human learning is thought to be unsupervised. For example, children do not receive labels for all the objects they encounter in their environment. In contrast, many machine learning algorithms, such as convolutional neural networks, require supervision in the form of labeled images. The goal of this project is to better understand how humans leverage the statistics of the world and thereby reduce their dependency on supervised training. The project will integrate existing approaches with novel algorithms in order to better understand how unsupervised learning yields feature representations that support high-level cognitive behavior, such as visual categorization. In addition to uncovering embedding spaces (e.g., for images, words, etc.) through unsupervised learning, we are interested in developing algorithms that can map between different embedding spaces (i.e., manifold alignment). This project will require integrating new code and results with a team repository.

## 2. Relating the brain to artificial neural networks through embedding spaces
Artificial neural networks (ANN) are useful tools both for doing supervised learning and for creating embedding spaces. Furthermore, they have even proved to have predictive power for the visual ventral stream in the human brain. This project seeks to reverse the direction of influence by using neural embedding spaces derived from fMRI data (e.g., BOLD5000) to improve the interpretability of ANN solutions. Thus, the goal is to tune ANN solutions to be more brain-like by leveraging embedding spaces inferred from fMRI and other data. One offshot of this project is introducing topological constraints into neural networks to make them more brain-like (and hopefully perform better too).

## 3. Attentional mechanisms for convolutional neural networks
Recent work has related Convolutional Neural Networks (CNN) to the human visual system. However, standard CNNs lacks an essential human ability, namely the ability to selectively attend to information according to the task context. This project aims to endow CNNs with this ability. We focus on featural as opposed to spatial attention. Spatial attention is directed toward a spatial location in an image whereas featural attention can be more diffuse. For example, when searching for one's dog, one may be more sensitive to features that reflect the colour and texture of the dog's fur irrespective of location. The general project aim is to both improve machine learning models and to create better models of human performance.

## 4. Heuristic regularisers for neural networks
[Recent work](https://arxiv.org/abs/2010.02610) in the lab has focused on generalizing ridge regression with robust priors derived from decision heuristics that humans use. Instead of centering a model's solution on the zero vector, heuristics suggest other sensible targets. Our approach is readily extended to the regularisation of neural networks. Artificial neural networks (ANNs) are typically regularised with an L1 or L2 norm to avoid overfitting. This project involves the construction of human-like heuristics as priors on the weights of ANNs. The goal is to selectively insert such priors at certain layers in the network to track improvements in performance, robustness, and interpretability.
